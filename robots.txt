# Ermögliche vollständiges Crawling für Google, Ahrefs und Semrush
User-agent: Googlebot
Allow: /

User-agent: AhrefsBot
Allow: /

User-agent: SemrushBot
Allow: /

# Allgemeine Richtlinien für alle anderen Bots
User-agent: *
Allow: /

# Ausnahme für spezifische sensible Bereiche
Disallow: /cgi-bin/
Disallow: /private/
Disallow: /tmp/
Disallow: /logs/
Disallow: /secret/
Disallow: /admin/
Disallow: /config.php
Disallow: /db_backup.php

# Sicherstellen, dass PHP-Seiten erlaubt sind
Allow: /*.php$
Allow: /maps
Allow: /blog/


# Erlaube das Crawlen aller CSS, JS und Bilddateien (wichtig für das korrekte Rendering in den Suchergebnissen)
Allow: /*.css$
Allow: /*.js$
Allow: /*.jpg$
Allow: /*.jpeg$
Allow: /*.png$
Allow: /*.gif$
Allow: /*.webp$
Allow: /*.svg$
Allow: /*.json$
Allow: /*.webp$
Allow: /*.ico$
Allow: /*.xml$


# Erlaube den Zugriff auf die Sitemap
Sitemap: https://www.webdesign-alcor.at/sitemap.xml

# Crawl-Delay für Bots, die dies unterstützen (falls nötig)
Crawl-Delay: 10


